import asyncio
import os
import re
import json
from datetime import datetime, timedelta, date
from zoneinfo import ZoneInfo
from calendar import monthrange
from collections import OrderedDict

import requests
from openpyxl import Workbook, load_workbook
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment, Font
from playwright.async_api import async_playwright

# Google Drive
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from google.oauth2.credentials import Credentials

# -------------------------
# ì„¤ì •
# -------------------------
KST = ZoneInfo("Asia/Seoul")
URL = "https://m.oliveyoung.co.kr/m/mtn?menu=ranking&tab=brands"

OUTPUT_DIR = "data"
XLSX_NAME = "ì˜¬ë¦¬ë¸Œì˜_ë¸Œëœë“œ_ìˆœìœ„.xlsx"
OUTPUT_PATH = os.path.join(OUTPUT_DIR, XLSX_NAME)

# Secrets (í™˜ê²½ë³€ìˆ˜)
SLACK_WEBHOOK_URL   = os.environ.get("SLACK_WEBHOOK_URL", "")
GDRIVE_FOLDER_ID    = os.environ.get("GDRIVE_FOLDER_ID", "")
GOOGLE_CLIENT_ID    = os.environ.get("GOOGLE_CLIENT_ID", "")
GOOGLE_CLIENT_SECRET= os.environ.get("GOOGLE_CLIENT_SECRET", "")
GOOGLE_REFRESH_TOKEN= os.environ.get("GOOGLE_REFRESH_TOKEN", "")

# -------------------------
# Playwright helpers
# -------------------------
async def maybe_click_brand_tab(page):
    """ìƒë‹¨ íƒ­ì—ì„œ 'ë¸Œëœë“œ ë­í‚¹'ì„ í™•ì‹¤íˆ ì„ íƒ"""
    # íƒ­ ì „í™˜(í…ìŠ¤íŠ¸/role ë²„íŠ¼ ë“± ì—¬ëŸ¬ ë°©ì‹ ì‹œë„)
    selectors = [
        "text=ë¸Œëœë“œ ë­í‚¹",                      # ì¼ë°˜ í…ìŠ¤íŠ¸
        "role=tab[name='ë¸Œëœë“œ ë­í‚¹']",          # tab role
        "button:has-text('ë¸Œëœë“œ ë­í‚¹')",
        "a:has-text('ë¸Œëœë“œ ë­í‚¹')",
    ]
    for sel in selectors:
        try:
            el = await page.wait_for_selector(sel, timeout=2000)
            if el:
                await el.click(timeout=1000)
                await page.wait_for_timeout(600)
                break
        except Exception:
            pass

async def close_banners(page):
    """ì•±ìœ ë„/íŒì—… ë‹«ê¸°(ìˆì„ ë•Œë§Œ)"""
    candidates = [
        "[aria-label*='ë‹«ê¸°']",
        "button[aria-label*='ë‹«ê¸°']",
        "[class*='btn_close']",
        "text=ë‹«ê¸°",
        "text=ì·¨ì†Œ",
        "text=ë‚˜ì¤‘ì—"
    ]
    for sel in candidates:
        try:
            el = await page.query_selector(sel)
            if el:
                await el.click(timeout=600)
                await page.wait_for_timeout(200)
        except Exception:
            pass

async def scroll_to_bottom(page, pause_ms=800, max_loops=28):
    """ë¬´í•œ ìŠ¤í¬ë¡¤(ë¸Œëœë“œ 100ìœ„ê¹Œì§€ ë¡œë“œ)"""
    last_h = 0
    for _ in range(max_loops):
        try:
            h = await page.evaluate("document.body.scrollHeight")
            if h == last_h:
                break
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await page.wait_for_timeout(pause_ms)
            last_h = h
        except Exception:
            break

def _looks_like_brand(text: str) -> bool:
    """ë¸Œëœë“œ í›„ë³´ í•„í„°: ë„ˆë¬´ ê¸´ ë¬¸ì¥/ê°€ê²©/í”„ë¡œëª¨ì…˜/ì œí’ˆëª… ë“± ì œê±°"""
    if not text:
        return False
    t = text.strip()
    if len(t) < 2 or len(t) > 30:
        return False
    # ì œí’ˆì— í”í•œ í† í°/ë‹¨ìœ„/ìˆ«ì/í”„ë¡œëª¨ì…˜ ë‹¨ì–´ ì œê±°
    ban = ["ì„¸ì¼", "íŠ¹ê°€", "ì¿ í°", "ê¸°íš", "ì„¸íŠ¸", "ì¦ì •", "êµ¬ì„±", "ë§ˆìŠ¤í¬",
           "íŒ¨ë“œ", "í¬ë¦¼", "í† ë„ˆ", "ì„¸ëŸ¼", "ìƒ´í‘¸", "ì•°í”Œ", "ml", "g", "%", "ì›"]
    if any(b in t for b in ban):
        return False
    if re.search(r"\d", t):  # ìˆ«ì ë§ì´ í¬í•¨í•˜ë©´ ì œì™¸(ë­í‚¹ë²ˆí˜¸/ê°€ê²© ë“±)
        # ë‹¨, ë¸Œëœë“œëª…ì´ ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° ì œì™¸
        return False
    # ì„¤ëª…ì„± ê¸´ ë¬¸ì¥ì€ ì œì™¸(ê³µë°± 6ë‹¨ì–´ ì´ˆê³¼)
    if len(t.split()) > 6:
        return False
    return True

async def extract_brands_robust(page):
    """ì—¬ëŸ¬ êµ¬ì¡°ë¥¼ ë™ì‹œì— ì‹œë„í•˜ì—¬ Top100 ë¸Œëœë“œë¥¼ ìµœëŒ€í•œ ì•ˆì •ì ìœ¼ë¡œ ìˆ˜ì§‘"""
    brands = []

    # 1) ëª…ì‹œì  í´ë˜ìŠ¤ í›„ë³´ì—ì„œ ìˆ˜ì§‘
    brand_name_selectors = [
        ".brand", ".brandName", ".tx_brand", ".brand-name",
        "strong[class*='brand']", "span[class*='brand']", "em[class*='brand']",
        ".tit", ".name", ".txt"  # ì¢…ì¢… 'ë©”ë””í' ê°™ì€ í•œê¸€ì´ ì—¬ê¸° ë“¤ì–´ê°
    ]
    for sel in brand_name_selectors:
        try:
            nodes = await page.query_selector_all(sel)
            for n in nodes:
                try:
                    t = (await n.inner_text()).strip()
                    if _looks_like_brand(t):
                        brands.append(t)
                except Exception:
                    pass
        except Exception:
            pass

    # 2) ë¡œê³  img altì—ì„œ ìˆ˜ì§‘ (ì˜ë¬¸ ë¸Œëœë“œ ë¡œê³ ê°€ altì— ë§ì€ í¸)
    try:
        imgs = await page.query_selector_all("img[alt]")
        for im in imgs:
            try:
                alt = (await im.get_attribute("alt")) or ""
                alt = alt.strip()
                if _looks_like_brand(alt):
                    brands.append(alt)
            except Exception:
                pass
    except Exception:
        pass

    # 3) ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ í…ìŠ¤íŠ¸ ë°±ì—…(êµ¬ì¡°ê°€ ë°”ë€Œì—ˆì„ ë•Œ)
    try:
        items = await page.query_selector_all("ul li, ol li")
        for li in items:
            try:
                raw = (await li.inner_text()).strip()
                if not raw:
                    continue
                # ì¤„ ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ ê°€ì¥ 'ë¸Œëœë“œìŠ¤ëŸ¬ìš´' í›„ë³´ ì„ íƒ
                lines = [re.sub(r"\s+", " ", s).strip() for s in raw.splitlines()]
                for s in lines:
                    s2 = re.sub(r"^[#\d\.\-\)\(]+", "", s).strip()
                    if _looks_like_brand(s2):
                        brands.append(s2)
                        break
            except Exception:
                pass
    except Exception:
        pass

    # ì •ë¦¬: ìˆœì„œ ìœ ì§€ ì¤‘ë³µ ì œê±°
    uniq = list(OrderedDict.fromkeys([b for b in brands if b]))
    # ë„ˆë¬´ ì¼ë°˜/ì¡ìŒ ë¬¸ìì—´ ì œê±°(í˜ì´ì§€ ê³µí†µ ë‹¨ì–´)
    junk = {"ë¸Œëœë“œ", "ë­í‚¹", "íŒë§¤", "ì˜¨ë¼ì¸", "ì¼ê°„", "ì£¼ê°„", "ì›”ê°„", "ë”ë³´ê¸°"}
    cleaned = [x for x in uniq if x not in junk]
    return cleaned[:100]

async def scrape_top100():
    async with async_playwright() as p:
        iphone = p.devices.get("iPhone 13 Pro")
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(**iphone, locale="ko-KR")
        page = await context.new_page()

        await page.goto(URL, wait_until="domcontentloaded", timeout=60_000)
        await page.wait_for_timeout(1200)
        await close_banners(page)
        await maybe_click_brand_tab(page)
        await page.wait_for_timeout(800)

        await scroll_to_bottom(page, pause_ms=700, max_loops=30)

        brands = await extract_brands_robust(page)

        # ë””ë²„ê·¸ ì•„ì›ƒí’‹ (100ê°œ ë¯¸ë§Œì´ë©´ HTML/ìŠ¤í¬ë¦°ìƒ· ì €ì¥)
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        if len(brands) < 100:
            try:
                await page.screenshot(path=os.path.join(OUTPUT_DIR, "brand_debug.png"), full_page=True)
                html = await page.content()
                with open(os.path.join(OUTPUT_DIR, "brand_debug.html"), "w", encoding="utf-8") as f:
                    f.write(html)
                print(f"[ë””ë²„ê·¸] brand_debug.* ì €ì¥ (ì¶”ì¶œ {len(brands)}ê°œ)")
            except Exception as e:
                print(f"[ë””ë²„ê·¸ ì €ì¥ ì‹¤íŒ¨] {e}")

        await context.close()
        await browser.close()
        return brands

# -------------------------
# ì—‘ì…€: ì›” ì‹œíŠ¸ ìë™ ìƒì„±/ê°±ì‹ 
# -------------------------
def month_sheet_name(dt: datetime) -> str:
    return f"{dt.strftime('%y')}ë…„ {dt.month}ì›”"  # ì˜ˆ: 25ë…„ 9ì›”

def ensure_month_sheet(wb, dt: datetime):
    name = month_sheet_name(dt)
    if name in wb.sheetnames:
        ws = wb[name]
    else:
        ws = wb.create_sheet(title=name)
        setup_layout(ws, dt)
    return ws

def setup_layout(ws, dt: datetime):
    last_day = monthrange(dt.year, dt.month)[1]
    ws["A1"] = "ë¸Œëœë“œ ìˆœìœ„ (ì˜¬ë¦¬ë¸Œì˜ ì•± ê¸°ì¤€)"
    ws["A1"].font = Font(bold=True, size=12)
    ws.merge_cells(start_row=1, start_column=1, end_row=1, end_column=1 + last_day)

    ws["A2"] = "ì¼ì"
    for d in range(1, last_day + 1):
        ws.cell(row=2, column=1 + d).value = f"{d}ì¼"

    ws["A3"] = "ìš”ì¼"
    for d in range(1, last_day + 1):
        wd = date(dt.year, dt.month, d).weekday()
        ws.cell(row=3, column=1 + d).value = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"][wd]

    ws["A4"] = "ë¹„ê³ "
    for r in range(1, 101):
        ws.cell(row=4 + r, column=1).value = r

    for r in range(1, 5 + 100):
        for c in range(1, 1 + last_day + 1):
            ws.cell(row=r, column=c).alignment = Alignment(vertical="center")
    ws.column_dimensions["A"].width = 8
    for d in range(1, last_day + 1):
        ws.column_dimensions[get_column_letter(1 + d)].width = 18

def write_today(ws, now: datetime, brands):
    col = 1 + now.day
    for i in range(100):
        ws.cell(row=5 + i, column=col).value = brands[i] if i < len(brands) else None

def read_rank_map(ws, day: int):
    col = 1 + day
    ranks = {}
    for i in range(100):
        name = ws.cell(row=5 + i, column=col).value
        if name:
            ranks[str(name).strip()] = i + 1
    return ranks

def get_yesterday_rank_map(wb, now: datetime):
    y = now - timedelta(days=1)
    sheet_name_y = month_sheet_name(y)
    if sheet_name_y in wb.sheetnames:
        ws_y = wb[sheet_name_y]
        try:
            return read_rank_map(ws_y, y.day)
        except Exception:
            pass
    return {}

def save_excel_and_get_yesterday_map(brands):
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    now = datetime.now(KST)

    if os.path.exists(OUTPUT_PATH):
        wb = load_workbook(OUTPUT_PATH)
    else:
        wb = Workbook()
        if "Sheet" in wb.sheetnames and len(wb.sheetnames) == 1:
            wb.remove(wb["Sheet"])

    ws = ensure_month_sheet(wb, now)
    if ws.cell(row=2, column=2).value is None:
        setup_layout(ws, now)

    ymap = get_yesterday_rank_map(wb, now)
    write_today(ws, now, brands)
    wb.save(OUTPUT_PATH)
    return ymap, now

# -------------------------
# Slack: Top10 ì•Œë¦¼ (ì „ì¼ ëŒ€ë¹„ ë“±ë½)
# -------------------------
def build_delta(today_rank, yesterday_rank):
    if yesterday_rank is None:
        return "(new)"
    diff = yesterday_rank - today_rank
    if diff > 0:
        return f"(â†‘{diff})"
    elif diff < 0:
        return f"(â†“{abs(diff)})"
    else:
        return "(-)"

def post_slack_top10(brands, ymap, now):
    if not SLACK_WEBHOOK_URL:
        print("[ê²½ê³ ] SLACK_WEBHOOK_URL ë¯¸ì„¤ì • â€” ìŠ¬ë™ ì „ì†¡ ìƒëµ")
        return
    top10 = brands[:10]
    lines = []
    for idx, name in enumerate(top10, start=1):
        y_rank = ymap.get(name)
        delta = build_delta(idx, y_rank)
        lines.append(f"{idx}. {delta} {name}")

    title = f"ğŸ“Š ì˜¬ë¦¬ë¸Œì˜ ë°ì¼ë¦¬ ë¸Œëœë“œ ë­í‚¹ Top10 â€” {now.strftime('%Y-%m-%d')} (KST)"
    body = "\n".join(lines)
    payload = {
        "blocks": [
            {"type": "header", "text": {"type": "plain_text", "text": title, "emoji": True}},
            {"type": "section", "text": {"type": "mrkdwn", "text": body}},
        ]
    }
    try:
        r = requests.post(SLACK_WEBHOOK_URL, data=json.dumps(payload),
                          headers={"Content-Type":"application/json"}, timeout=10)
        r.raise_for_status()
        print("[ìŠ¬ë™] Top10 ì „ì†¡ ì™„ë£Œ")
    except Exception as e:
        print(f"[ìŠ¬ë™] ì „ì†¡ ì‹¤íŒ¨: {e}")

# -------------------------
# Google Drive ì—…ë¡œë“œ
# -------------------------
def build_drive_service():
    if not (GOOGLE_CLIENT_ID and GOOGLE_CLIENT_SECRET and GOOGLE_REFRESH_TOKEN and GDRIVE_FOLDER_ID):
        print("[ê²½ê³ ] êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì‹œí¬ë¦¿ì´ ì—†ì–´ ì—…ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    creds = Credentials(
        token=None,
        refresh_token=GOOGLE_REFRESH_TOKEN,
        token_uri="https://oauth2.googleapis.com/token",
        client_id=GOOGLE_CLIENT_ID,
        client_secret=GOOGLE_CLIENT_SECRET,
        scopes=["https://www.googleapis.com/auth/drive"]
    )
    return build("drive", "v3", credentials=creds)

def find_file_in_folder(service, folder_id, name):
    q = f"name = '{name}' and '{folder_id}' in parents and trashed = false"
    res = service.files().list(q=q, fields="files(id, name)", pageSize=1).execute()
    files = res.get("files", [])
    return files[0]["id"] if files else None

def upload_or_update_to_drive(filepath, folder_id):
    service = build_drive_service()
    if not service:
        return
    file_id = find_file_in_folder(service, folder_id, os.path.basename(filepath))
    media = MediaFileUpload(filepath, mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", resumable=True)
    if file_id:
        service.files().update(fileId=file_id, media_body=media).execute()
        print(f"[ë“œë¼ì´ë¸Œ] ê¸°ì¡´ íŒŒì¼ ê°±ì‹  ì™„ë£Œ: {filepath}")
    else:
        file_metadata = {"name": os.path.basename(filepath), "parents": [folder_id]}
        service.files().create(body=file_metadata, media_body=media, fields="id").execute()
        print(f"[ë“œë¼ì´ë¸Œ] ìƒˆ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {filepath}")

# -------------------------
# main
# -------------------------
async def main():
    brands = await scrape_top100()
    # ì´ì „ì—” ì‹¤íŒ¨ ì‹œ RuntimeErrorë¡œ ì¢…ë£Œ â†’ ì´ì œëŠ” ê²½ê³ ë§Œ ì¶œë ¥í•˜ê³  ì§„í–‰(ë””ë²„ê·¸ íŒŒì¼ ì €ì¥ë¨)
    if not brands:
        print("[ê²½ê³ ] ë¸Œëœë“œ 0ê°œ ìˆ˜ì§‘ â€” ë””ë²„ê·¸ HTML/PNG í™•ì¸ í•„ìš”")
    else:
        print(f"[INFO] ë¸Œëœë“œ {len(brands)}ê°œ ìˆ˜ì§‘")

    ymap, now = save_excel_and_get_yesterday_map(brands)
    post_slack_top10(brands, ymap, now)
    upload_or_update_to_drive(OUTPUT_PATH, GDRIVE_FOLDER_ID)

if __name__ == "__main__":
    asyncio.run(main())
