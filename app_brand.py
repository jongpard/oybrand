# -*- coding: utf-8 -*-
"""
ì˜¬ë¦¬ë¸Œì˜ ëª¨ë°”ì¼ 'ë¸Œëœë“œ ë­í‚¹' ìˆ˜ì§‘ (Oxylabs Realtime API ì‚¬ìš©)
- ë Œë”ëœ HTMLì„ APIë¡œ ë°›ì•„ brandsInfo.brandNameë§Œ ì¶”ì¶œ(Top100)
- ì—‘ì…€: ì›” ì‹œíŠ¸ ìë™ ìƒì„±, ë§¤ì¼ ì—´ ë®ì–´ì“°ê¸° ê°±ì‹ 
- ìŠ¬ë™: Top10 (ì „ì¼ ëŒ€ë¹„ ë“±ë½ í‘œê¸°)
- êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ(ì„ íƒ)
"""

import os
import re
import json
import requests
from datetime import datetime, timedelta, date
from zoneinfo import ZoneInfo
from calendar import monthrange
from collections import OrderedDict

from openpyxl import Workbook, load_workbook
from openpyxl.utils import get_column_letter
from openpyxl.styles import Alignment, Font
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from google.oauth2.credentials import Credentials

# -------------------------
# ì„¤ì •
# -------------------------
KST = ZoneInfo("Asia/Seoul")
URL = "https://m.oliveyoung.co.kr/m/mtn?menu=ranking&tab=brands"

OUTPUT_DIR = "data"
XLSX_NAME = "ì˜¬ë¦¬ë¸Œì˜_ë¸Œëœë“œ_ìˆœìœ„.xlsx"
OUTPUT_PATH = os.path.join(OUTPUT_DIR, XLSX_NAME)

# ì‹œí¬ë¦¿/í™˜ê²½ë³€ìˆ˜
SLACK_WEBHOOK_URL    = os.environ.get("SLACK_WEBHOOK_URL", "")
GDRIVE_FOLDER_ID     = os.environ.get("GDRIVE_FOLDER_ID", "")
GOOGLE_CLIENT_ID     = os.environ.get("GOOGLE_CLIENT_ID", "")
GOOGLE_CLIENT_SECRET = os.environ.get("GOOGLE_CLIENT_SECRET", "")
GOOGLE_REFRESH_TOKEN = os.environ.get("GOOGLE_REFRESH_TOKEN", "")

SCRAPING_API         = os.environ.get("SCRAPING_API", "").lower()   # ë°˜ë“œì‹œ "oxylabs"
OXY_USER             = os.environ.get("OXY_USER", "")
OXY_PASS             = os.environ.get("OXY_PASS", "")

# -------------------------
# ìœ í‹¸/ì •ê·œí™”
# -------------------------
CODE_PATTERNS = [
    re.compile(r"^[A-Z]\d{4,}$"),  # A000688 ë“±
    re.compile(r"^\d{4,}$"),       # ìˆ«ì ê¸´ ì½”ë“œ
]

def normalize_brand_text(t: str) -> str | None:
    if not isinstance(t, str):
        return None
    s = re.sub(r"\s+", " ", t).strip()
    if not s:
        return None
    # ì½”ë“œ/ìˆ«ì/ë¶ˆí•„ìš” ê¼¬ë¦¬í‘œ ì»·
    for p in CODE_PATTERNS:
        if p.match(s):
            return None
    if re.search(r"\d", s):
        return None
    s = re.sub(r"\s*(ë¸Œëœë“œ\s*ì¸ë„¤ì¼|ë¡œê³ .*|ì´ë¯¸ì§€.*|íƒ€ì´í‹€.*)$", "", s).strip()
    if len(s) > 30 or len(s.split()) > 6:
        return None
    if len(s) == 1 and not re.fullmatch(r"[ê°€-í£]", s):
        return None
    if s.lower() in {"brand","logo","image","title"}:
        return None
    return s

# -------------------------
# Oxylabs Realtime API
# -------------------------
def fetch_html_via_oxylabs(url: str) -> str | None:
    if SCRAPING_API != "oxylabs" or not (OXY_USER and OXY_PASS):
        print("[Oxylabs] ì‹œí¬ë¦¿ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    try:
        payload = {
            "source": "universal",
            "url": url,
            "render": "html",                # JS ë Œë”ë§
            "geo_location": "South Korea",   # í•œêµ­ ì§€ë¦¬
            "user_agent_type": "mobile"      # ëª¨ë°”ì¼ UA
        }
        r = requests.post(
            "https://realtime.oxylabs.io/v1/queries",
            auth=(OXY_USER, OXY_PASS),
            headers={"Content-Type": "application/json"},
            data=json.dumps(payload),
            timeout=60,
        )
        r.raise_for_status()
        data = r.json()
        results = data.get("results") or []
        if results and "content" in results[0]:
            return results[0]["content"]
        print("[Oxylabs] content ì—†ìŒ")
    except Exception as e:
        print(f"[Oxylabs] ìš”ì²­ ì‹¤íŒ¨: {e}")
    return None

def extract_brands_from_html(html: str) -> list[str]:
    """ë Œë”ëœ HTMLì—ì„œ brandsInfo.brandNameë§Œ ì¶”ì¶œ(ìˆœì„œ=ë­í‚¹)"""
    if not html:
        return []
    names = []
    # ëŒ€í‘œ íŒ¨í„´: "brandsInfo": { ... "brandName": "ë©”ë””í" ... }
    for m in re.finditer(r'brandsInfo"\s*:\s*{[^}]*"brandName"\s*:\s*"([^"]+)"', html):
        nm = normalize_brand_text(m.group(1))
        if nm:
            names.append(nm)
    # ë°±ì—…: brandName í‚¤ ì „ì²´ íƒìƒ‰
    if not names:
        for m in re.finditer(r'"brandName"\s*:\s*"([^"]+)"', html):
            nm = normalize_brand_text(m.group(1))
            if nm:
                names.append(nm)
    # ìˆœì„œ ìœ ì§€Â·ì¤‘ë³µ ì œê±°
    return list(OrderedDict.fromkeys(names))[:100]

# -------------------------
# ì—‘ì…€ (ì›” ì‹œíŠ¸ ìë™ ìƒì„±/ì˜¤ëŠ˜ ì—´ ê°±ì‹ )
# -------------------------
def month_sheet_name(dt: datetime) -> str:
    return f"{dt.strftime('%y')}ë…„ {dt.month}ì›”"

def ensure_month_sheet(wb, dt: datetime):
    name = month_sheet_name(dt)
    if name in wb.sheetnames:
        ws = wb[name]
    else:
        ws = wb.create_sheet(title=name)
        setup_layout(ws, dt)
    return ws

def setup_layout(ws, dt: datetime):
    last_day = monthrange(dt.year, dt.month)[1]
    ws["A1"] = "ë¸Œëœë“œ ìˆœìœ„ (ì˜¬ë¦¬ë¸Œì˜ ì•± ê¸°ì¤€)"
    ws["A1"].font = Font(bold=True, size=12)
    ws.merge_cells(start_row=1, start_column=1, end_row=1, end_column=1 + last_day)

    ws["A2"] = "ì¼ì"
    for d in range(1, last_day + 1):
        ws.cell(row=2, column=1 + d).value = f"{d}ì¼"

    ws["A3"] = "ìš”ì¼"
    for d in range(1, last_day + 1):
        wd = date(dt.year, dt.month, d).weekday()
        ws.cell(row=3, column=1 + d).value = ["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼"][wd]

    ws["A4"] = "ë¹„ê³ "
    for r in range(1, 101):
        ws.cell(row=4 + r, column=1).value = r

    for r in range(1, 5 + 100):
        for c in range(1, 1 + last_day + 1):
            ws.cell(row=r, column=c).alignment = Alignment(vertical="center")
    ws.column_dimensions["A"].width = 8
    for d in range(1, last_day + 1):
        ws.column_dimensions[get_column_letter(1 + d)].width = 18

def write_today(ws, now: datetime, brands: list[str]):
    col = 1 + now.day
    for i in range(100):
        ws.cell(row=5 + i, column=col).value = brands[i] if i < len(brands) else None

def read_rank_map(ws, day: int):
    col = 1 + day
    ranks = {}
    for i in range(100):
        name = ws.cell(row=5 + i, column=col).value
        if name:
            ranks[str(name).strip()] = i + 1
    return ranks

def get_yesterday_rank_map(wb, now: datetime):
    y = now - timedelta(days=1)
    sheet_name_y = month_sheet_name(y)
    if sheet_name_y in wb.sheetnames:
        ws_y = wb[sheet_name_y]
        try:
            return read_rank_map(ws_y, y.day)
        except Exception:
            pass
    return {}

def save_excel_and_get_yesterday_map(brands: list[str]):
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    now = datetime.now(KST)

    if os.path.exists(OUTPUT_PATH):
        wb = load_workbook(OUTPUT_PATH)
    else:
        wb = Workbook()
        if "Sheet" in wb.sheetnames and len(wb.sheetnames) == 1:
            wb.remove(wb["Sheet"])

    ws = ensure_month_sheet(wb, now)
    if ws.cell(row=2, column=2).value is None:
        setup_layout(ws, now)

    ymap = get_yesterday_rank_map(wb, now)
    write_today(ws, now, brands)
    wb.save(OUTPUT_PATH)
    return ymap, now

# -------------------------
# ìŠ¬ë™ Top10
# -------------------------
def build_delta(today_rank, yesterday_rank):
    if yesterday_rank is None:
        return "(new)"
    diff = yesterday_rank - today_rank
    if diff > 0:
        return f"(â†‘{diff})"
    elif diff < 0:
        return f"(â†“{abs(diff)})"
    else:
        return "(-)"

def post_slack_top10(brands: list[str], ymap: dict, now: datetime):
    if not SLACK_WEBHOOK_URL:
        print("[ê²½ê³ ] SLACK_WEBHOOK_URL ë¯¸ì„¤ì • â€” ìŠ¬ë™ ì „ì†¡ ìƒëµ")
        return
    if not brands:
        print("[ìŠ¬ë™] ìˆ˜ì§‘ ê²°ê³¼ 0ê°œ â€” ì „ì†¡ ìƒëµ")
        return

    top10 = brands[:10]
    lines = []
    for idx, name in enumerate(top10, start=1):
        y_rank = ymap.get(name)
        delta = build_delta(idx, y_rank)
        lines.append(f"{idx}. {delta} {name}")

    title = f"ğŸ“Š ì˜¬ë¦¬ë¸Œì˜ ë°ì¼ë¦¬ ë¸Œëœë“œ ë­í‚¹ Top10 â€” {now.strftime('%Y-%m-%d')} (KST)"
    body = "\n".join(lines)

    payload = {
        "blocks": [
            {"type": "header", "text": {"type": "plain_text", "text": title, "emoji": True}},
            {"type": "section", "text": {"type": "mrkdwn", "text": body}},
        ]
    }
    try:
        r = requests.post(SLACK_WEBHOOK_URL, data=json.dumps(payload),
                          headers={"Content-Type": "application/json"}, timeout=12)
        r.raise_for_status()
        print("[ìŠ¬ë™] Top10 ì „ì†¡ ì™„ë£Œ")
    except Exception as e:
        print(f"[ìŠ¬ë™] ì „ì†¡ ì‹¤íŒ¨: {e}")

# -------------------------
# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ (ì„ íƒ)
# -------------------------
def build_drive_service():
    if not (GOOGLE_CLIENT_ID and GOOGLE_CLIENT_SECRET and GOOGLE_REFRESH_TOKEN and GDRIVE_FOLDER_ID):
        print("[ê²½ê³ ] êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì‹œí¬ë¦¿ì´ ì—†ì–´ ì—…ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    try:
        creds = Credentials(
            token=None,
            refresh_token=GOOGLE_REFRESH_TOKEN,
            token_uri="https://oauth2.googleapis.com/token",
            client_id=GOOGLE_CLIENT_ID,
            client_secret=GOOGLE_CLIENT_SECRET,
            scopes=["https://www.googleapis.com/auth/drive.file"],
        )
        return build("drive", "v3", credentials=creds)
    except Exception as e:
        print(f"[ë“œë¼ì´ë¸Œ] ì„œë¹„ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def find_file_in_folder(service, folder_id, name):
    q = f"name = '{name}' and '{folder_id}' in parents and trashed = false"
    res = service.files().list(q=q, fields="files(id, name)", pageSize=1).execute()
    files = res.get("files", [])
    return files[0]["id"] if files else None

def upload_or_update_to_drive(filepath, folder_id):
    service = build_drive_service()
    if not service:
        return
    try:
        file_id = find_file_in_folder(service, folder_id, os.path.basename(filepath))
        media = MediaFileUpload(
            filepath,
            mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            resumable=True,
        )
        if file_id:
            service.files().update(fileId=file_id, media_body=media).execute()
            print(f"[ë“œë¼ì´ë¸Œ] ê¸°ì¡´ íŒŒì¼ ê°±ì‹  ì™„ë£Œ: {filepath}")
        else:
            file_metadata = {"name": os.path.basename(filepath), "parents": [folder_id]}
            service.files().create(body=file_metadata, media_body=media, fields="id").execute()
            print(f"[ë“œë¼ì´ë¸Œ] ìƒˆ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {filepath}")
    except Exception as e:
        print(f"[ë“œë¼ì´ë¸Œ] ì—…ë¡œë“œ/ê°±ì‹  ì‹¤íŒ¨: {e}")

# -------------------------
# main
# -------------------------
def main():
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    html = fetch_html_via_oxylabs(URL)
    if html:
        # ë””ë²„ê·¸ ì €ì¥(í™•ì¸ìš©)
        try:
            with open(os.path.join(OUTPUT_DIR, "brand_debug.html"), "w", encoding="utf-8") as f:
                f.write(html[:200000])
        except Exception:
            pass
        brands = extract_brands_from_html(html)
    else:
        brands = []

    if not brands:
        print("[ê²½ê³ ] ë¸Œëœë“œ 0ê°œ ìˆ˜ì§‘ â€” Oxylabs ì„¤ì •/ì‘ë‹µ í™•ì¸ í•„ìš”")
    else:
        print(f"[INFO] ë¸Œëœë“œ {len(brands)}ê°œ ìˆ˜ì§‘")

    ymap, now = save_excel_and_get_yesterday_map(brands)
    post_slack_top10(brands, ymap, now)
    upload_or_update_to_drive(OUTPUT_PATH, GDRIVE_FOLDER_ID)

if __name__ == "__main__":
    main()
