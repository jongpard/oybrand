#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# brand_rank_app.py â€” ì˜¬ë¦¬ë¸Œì˜ ëª¨ë°”ì¼ ë¸Œëœë“œ ë­í‚¹ í¬ë¡¤ë§ (Playwright ì•ˆì •ì„± ê°•í™”)

import os
import re
import json
import logging
from io import BytesIO, StringIO
from datetime import datetime, timedelta, timezone

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup

# Playwright fallback
try:
    from playwright.sync_api import sync_playwright
    PLAYWRIGHT_AVAILABLE = True
except Exception:
    PLAYWRIGHT_AVAILABLE = False

# Google Drive (OAuth)
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload, MediaIoBaseDownload
from google.oauth2.credentials import Credentials as UserCredentials
from google.auth.transport.requests import Request as GoogleRequest

# ---------------- ì„¤ì •(ENV)
SLACK_WEBHOOK = os.environ.get("SLACK_WEBHOOK_URL", "").strip()
GOOGLE_CLIENT_ID = os.environ.get("GOOGLE_CLIENT_ID", "").strip()
GOOGLE_CLIENT_SECRET = os.environ.get("GOOGLE_CLIENT_SECRET", "").strip()
GOOGLE_REFRESH_TOKEN = os.environ.get("GOOGLE_REFRESH_TOKEN", "").strip()
GDRIVE_FOLDER_ID = os.environ.get("GDRIVE_FOLDER_ID", "").strip()

OUT_DIR = "rankings"
MAX_ITEMS = 100
TOP_WINDOW = 30
SCREENSHOT_PATH = "debug_screenshot.png" # ì—ëŸ¬ ë°œìƒ ì‹œ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ê²½ë¡œ

logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s: %(message)s")

# ---------------- ìœ í‹¸ (ì´ì „ê³¼ ë™ì¼)
def kst_now():
    return datetime.now(timezone.utc) + timedelta(hours=9)

def make_session():
    s = requests.Session()
    retries = Retry(total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])
    s.mount("https://", HTTPAdapter(max_retries=retries))
    s.headers.update({
        "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1",
        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
        "Referer": "https://m.oliveyoung.co.kr/m/main.do",
    })
    return s

# ---------------- íŒŒì‹±/ì •ì œ (ì´ì „ê³¼ ë™ì¼)
def parse_brand_html(html: str):
    soup = BeautifulSoup(html, "html.parser")
    list_items = soup.select("div.rank_brand_list > ul > li")
    
    results = []
    if not list_items:
        logging.warning("ë¸Œëœë“œ ë­í‚¹ ë¦¬ìŠ¤íŠ¸(.rank_brand_list > ul > li)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []

    for item in list_items[:MAX_ITEMS]:
        rank_node = item.select_one(".rank_num"); rank = int(rank_node.get_text(strip=True)) if rank_node else None
        brand_name_node = item.select_one(".brand_name"); brand_name = brand_name_node.get_text(strip=True) if brand_name_node else ""
        link_node = item.select_one("a.brand_item"); href = link_node.get("href") if link_node else ""
        if href and not href.startswith("http"): href = "https://m.oliveyoung.co.kr" + href
        product_name_node = item.select_one(".prd_name"); product_name = product_name_node.get_text(strip=True) if product_name_node else ""
        if rank and brand_name:
            results.append({"rank": rank, "brand_name": brand_name, "representative_product": product_name, "url": href})
    
    logging.info("parse_brand_html: %dê°œì˜ ë¸Œëœë“œ ìˆœìœ„ë¥¼ íŒŒì‹±í–ˆìŠµë‹ˆë‹¤.", len(results))
    return results

def fetch_brand_ranking_data():
    session = make_session()
    url = "https://m.oliveyoung.co.kr/m/mtn/ranking/getBrandRanking.do"
    try:
        logging.info("HTTP GET: %s", url)
        r = session.get(url, timeout=20)
        logging.info(" -> status=%s, ct=%s, len=%d", r.status_code, r.headers.get("Content-Type"), len(r.text or ""))
        if r.status_code != 200: return None, r.text[:800]
        items = parse_brand_html(r.text)
        return (items, r.text[:800]) if items else (None, r.text[:800])
    except Exception as e:
        logging.exception("HTTP ìš”ì²­ ì‹¤íŒ¨: %s", e)
        return None, str(e)

# --- âœ¨ ì•ˆì •ì„±ì´ ê°•í™”ëœ Playwright Fallback í•¨ìˆ˜ ---
def try_playwright_for_brands():
    if not PLAYWRIGHT_AVAILABLE:
        logging.warning("Playwright not available.")
        return None, None
    
    main_url = "https://m.oliveyoung.co.kr/m/main.do"
    ranking_url = "https://m.oliveyoung.co.kr/m/mtn/ranking/getBrandRanking.do"
    
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True, args=["--no-sandbox","--disable-dev-shm-usage"])
            context = browser.new_context(
                user_agent="Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1",
                locale="ko-KR",
                viewport={'width': 390, 'height': 844}
            )
            page = context.new_page()
            
            # 1. ë©”ì¸ í˜ì´ì§€ë¥¼ ë¨¼ì € ë°©ë¬¸í•˜ì—¬ ì„¸ì…˜ í™œì„±í™”
            logging.info("Playwright: Visiting main page first to get session cookies.")
            page.goto(main_url, wait_until="domcontentloaded", timeout=30000)
            page.wait_for_timeout(2000) # íŒì—… ë“± ë¡œë”© ëŒ€ê¸°
            
            # 2. ë¸Œëœë“œ ë­í‚¹ í˜ì´ì§€ë¡œ ì´ë™
            logging.info("Playwright: Navigating to brand ranking page.")
            page.goto(ranking_url, wait_until="networkidle", timeout=40000)
            
            # 3. ë­í‚¹ ë¦¬ìŠ¤íŠ¸ê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ìµœëŒ€ 20ì´ˆ ëŒ€ê¸°
            try:
                page.wait_for_selector("div.rank_brand_list > ul > li", timeout=20000)
                logging.info("Playwright: Ranking list element found.")
            except Exception as e:
                # íƒ€ì„ì•„ì›ƒ ë°œìƒ ì‹œ ìŠ¤í¬ë¦°ìƒ· ì €ì¥
                page.screenshot(path=SCREENSHOT_PATH)
                logging.error("Playwright: Timeout waiting for selector. Debug screenshot saved to %s", SCREENSHOT_PATH)
                raise e # ì—ëŸ¬ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œ catch ë¸”ë¡ìœ¼ë¡œ ë„˜ê¹€

            html = page.content()
            items = parse_brand_html(html)
            browser.close()
            return items, html[:800]
            
    except Exception as e:
        logging.exception("Playwright render error: %s", e)
        # ìŠ¤í¬ë¦°ìƒ· íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ì•„í‹°íŒ©íŠ¸ë¡œ ì—…ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ ê²½ë¡œ ë°˜í™˜
        return None, f"Playwright failed. Check screenshot artifact if available. Error: {str(e)}"

# ... (Google Drive, ë¶„ì„, Slack í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€) ...
# (ì´í•˜ ìƒëµ - ì´ì „ ë‹µë³€ì˜ Google Drive, ë¶„ì„, Slack, ë©”ì¸ í•¨ìˆ˜ ë¶€ë¶„ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤)

# ---------------- ë©”ì¸
def main():
    now_kst = kst_now()
    today_kst = now_kst.date()
    yesterday_kst = (now_kst - timedelta(days=1)).date()
    logging.info("Build: oy-brand-rank-app %s", today_kst.isoformat())

    # --- í¬ë¡¤ë§ ë¡œì§ (Playwright Fallback) ---
    logging.info("Start scraping brand ranking (HTTP First)")
    items, sample = fetch_brand_ranking_data()
    
    if not items:
        logging.warning("HTTP request failed, falling back to Playwright.")
        items, sample = try_playwright_for_brands()

    if not items:
        logging.error("Scraping failed completely. sample head: %s", (sample or "")[:500])
        send_slack_text(f"âŒ OliveYoung Mobile Brand Ranking scraping failed.\n{(sample or '')[:800]}")
        return 1
    
    # --- CSV ìƒì„± ë° ì—…ë¡œë“œ ---
    os.makedirs(OUT_DIR, exist_ok=True)
    fname_today = f"ì˜¬ë¦¬ë¸Œì˜_ë¸Œëœë“œë­í‚¹_{today_kst.isoformat()}.csv"
    header = ["rank", "brand_name", "representative_product", "url"]
    def q(s):
        if s is None: return ""
        s = str(s).replace('"', '""'); return f'"{s}"' if any(c in s for c in [',', '\n', '"']) else s
    lines = [",".join(header)]
    for it in items: lines.append(",".join([q(it.get(h)) for h in header]))
    csv_data = "\n".join(lines).encode("utf-8")
    path = os.path.join(OUT_DIR, fname_today)
    with open(path, "wb") as f: f.write(csv_data)
    logging.info("Saved CSV locally: %s", path)

    drive_service = build_drive_service_oauth()
    if drive_service and GDRIVE_FOLDER_ID:
        upload_csv_to_drive(drive_service, csv_data, fname_today, folder_id=GDRIVE_FOLDER_ID)
    else:
        logging.warning("OAuth Drive ë¯¸ì„¤ì • ë˜ëŠ” í´ë”ID ëˆ„ë½ -> ì—…ë¡œë“œ ìŠ¤í‚µ")

    # --- ì „ì¼ ë°ì´í„° ë¡œë“œ ë° ë¶„ì„ ---
    prev_items = None
    if drive_service and GDRIVE_FOLDER_ID:
        fname_yesterday = f"ì˜¬ë¦¬ë¸Œì˜_ë¸Œëœë“œë­í‚¹_{yesterday_kst.isoformat()}.csv"
        y_file = find_csv_by_exact_name(drive_service, GDRIVE_FOLDER_ID, fname_yesterday)
        if y_file:
            prev_csv_text = download_file_from_drive(drive_service, y_file.get("id"))
            if prev_csv_text:
                prev_items = []
                try:
                    import csv
                    sio = StringIO(prev_csv_text)
                    rdr = csv.DictReader(sio)
                    for r in rdr:
                        try: r['rank'] = int(r.get('rank', 0)); prev_items.append(r)
                        except (ValueError, TypeError): continue
                except Exception as e: logging.exception("Previous CSV parse failed: %s", e)
    
    up, down, chart_ins, rank_out, in_out_count = analyze_brand_trends(items, prev_items or [], TOP_WINDOW)

    # --- Slack ë©”ì‹œì§€ êµ¬ì„± ---
    title = f"*ì˜¬ë¦¬ë¸Œì˜ ëª¨ë°”ì¼ ë¸Œëœë“œ ë­í‚¹ 100* ({now_kst.strftime('%Y-%m-%d %H:%M KST')})"
    out_lines = [title]
    out_lines.append("\n*ğŸ† TOP 10 ë¸Œëœë“œ*")
    for it in items[:10]: out_lines.append(f"{it.get('rank')}. <{it.get('url')}|{it.get('brand_name')}>")
    def fmt_brand_move(brand, prev, cur): return f"- {brand} {prev}ìœ„ â†’ {cur}ìœ„ ({'â†‘' if prev > cur else 'â†“'}{abs(prev - cur)})"
    out_lines.append("\n*ğŸ”¥ ê¸‰ìƒìŠ¹*")
    for m in up[:3]: out_lines.append(fmt_brand_move(m["brand_name"], m["prev_rank"], m["rank"]))
    out_lines.append("\n*ğŸ†• ë‰´ë­ì»¤*")
    for t in chart_ins[:3]: out_lines.append(f"- {t['brand_name']} NEW â†’ {t['rank']}ìœ„")
    out_lines.append("\n*ğŸ“‰ ê¸‰í•˜ë½ & ë­í¬ì•„ì›ƒ*")
    for m in down[:3]: out_lines.append(fmt_brand_move(m["brand_name"], m["prev_rank"], m["rank"]))
    for ro in rank_out[:2]: out_lines.append(f"- {ro['brand_name']} {ro['rank']}ìœ„ â†’ OUT")
    out_lines.append(f"\n*â†” ë­í¬ ì¸&ì•„ì›ƒ*: {in_out_count}ê°œ ë¸Œëœë“œ ë³€ë™")

    send_slack_text("\n".join(out_lines))
    logging.info("Done.")
    return 0

if __name__ == "__main__":
    exit(main())```

### **ì›Œí¬í”Œë¡œìš° íŒŒì¼ ìˆ˜ì • (`brand_crawler.yml`)**

ì—ëŸ¬ ë°œìƒ ì‹œ ìŠ¤í¬ë¦°ìƒ·ì„ ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥í•˜ì—¬ ì›ì¸ì„ ì‰½ê²Œ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ì›Œí¬í”Œë¡œìš° íŒŒì¼ì— í•œ ë‹¨ê³„ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

```yaml
# .github/workflows/brand_crawler.yml

name: ì˜¬ë¦¬ë¸Œì˜ ë¸Œëœë“œ ë­í‚¹ í¬ë¡¤ëŸ¬

on:
  workflow_dispatch:
  schedule:
    - cron: '00 16 * * *'

jobs:
  build-and-run:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 google-api-python-client google-auth-httplib2 google-auth-oauthlib playwright

      - name: Install Playwright Browsers
        run: playwright install --with-deps chromium

      - name: Run Brand Ranking Crawler
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
          GOOGLE_REFRESH_TOKEN: ${{ secrets.GOOGLE_REFRESH_TOKEN }}
          GDRIVE_FOLDER_ID: ${{ secrets.GDRIVE_FOLDER_ID }}
        run: python brand_rank_app.py

      # --- âœ¨ ìˆ˜ì •/ì¶”ê°€ëœ ë¶€ë¶„ ---
      - name: Upload debug screenshot on failure
        # ìŠ¤í¬ë¦½íŠ¸ê°€ ì‹¤íŒ¨í–ˆì„ ë•Œë§Œ ì´ ë‹¨ê³„ë¥¼ ì‹¤í–‰
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: debug-screenshot
          path: debug_screenshot.png # ìŠ¤í¬ë¦½íŠ¸ê°€ ìƒì„±í•œ ìŠ¤í¬ë¦°ìƒ· íŒŒì¼

      - name: Upload ranking data artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: brand-ranking-csv
          path: rankings/
