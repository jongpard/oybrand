#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# brand_rank_app.py â€” ì˜¬ë¦¬ë¸Œì˜ ëª¨ë°”ì¼ ë¸Œëœë“œ ë­í‚¹ í¬ë¡¤ë§ (Playwright Stealth ì ìš© ìµœì¢…ë³¸)

import os
import re
import json
import logging
from io import BytesIO, StringIO
from datetime import datetime, timedelta, timezone

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup

# Playwright & Stealth
try:
    from playwright.sync_api import sync_playwright
    from playwright_stealth import stealth_sync # âœ¨ Stealth ë¼ì´ë¸ŒëŸ¬ë¦¬ import
    PLAYWRIGHT_AVAILABLE = True
except Exception:
    PLAYWRIGHT_AVAILABLE = False

# Google Drive (OAuth)
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload, MediaIoBaseDownload
from google.oauth2.credentials import Credentials as UserCredentials
from google.auth.transport.requests import Request as GoogleRequest

# ---------------- ì„¤ì •(ENV)
SLACK_WEBHOOK = os.environ.get("SLACK_WEBHOOK_URL", "").strip()
GOOGLE_CLIENT_ID = os.environ.get("GOOGLE_CLIENT_ID", "").strip()
GOOGLE_CLIENT_SECRET = os.environ.get("GOOGLE_CLIENT_SECRET", "").strip()
GOOGLE_REFRESH_TOKEN = os.environ.get("GOOGLE_REFRESH_TOKEN", "").strip()
GDRIVE_FOLDER_ID = os.environ.get("GDRIVE_FOLDER_ID", "").strip()

OUT_DIR = "rankings"
MAX_ITEMS = 100
TOP_WINDOW = 30
SCREENSHOT_PATH = "debug_screenshot.png"

logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s: %(message)s")

# ... (ìœ í‹¸, íŒŒì‹± í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼) ...
def kst_now():
    return datetime.now(timezone.utc) + timedelta(hours=9)

def make_session():
    s = requests.Session()
    retries = Retry(total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])
    s.mount("https://", HTTPAdapter(max_retries=retries))
    s.headers.update({
        "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1",
        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
        "Referer": "https://m.oliveyoung.co.kr/m/main.do",
    })
    return s

def parse_brand_html(html: str):
    soup = BeautifulSoup(html, "html.parser")
    list_items = soup.select("div.rank_brand_list > ul > li")
    results = []
    if not list_items: return []
    for item in list_items[:MAX_ITEMS]:
        rank_node = item.select_one(".rank_num"); rank = int(rank_node.get_text(strip=True)) if rank_node else None
        brand_name_node = item.select_one(".brand_name"); brand_name = brand_name_node.get_text(strip=True) if brand_name_node else ""
        link_node = item.select_one("a.brand_item"); href = link_node.get("href") if link_node else ""
        if href and not href.startswith("http"): href = "https://m.oliveyoung.co.kr" + href
        product_name_node = item.select_one(".prd_name"); product_name = product_name_node.get_text(strip=True) if product_name_node else ""
        if rank and brand_name:
            results.append({"rank": rank, "brand_name": brand_name, "representative_product": product_name, "url": href})
    logging.info("parse_brand_html: %dê°œì˜ ë¸Œëœë“œ ìˆœìœ„ë¥¼ íŒŒì‹±í–ˆìŠµë‹ˆë‹¤.", len(results))
    return results

def fetch_brand_ranking_data(): # ì´ í•¨ìˆ˜ëŠ” ì´ì œ ê±°ì˜ í•­ìƒ ì‹¤íŒ¨í•˜ì§€ë§Œ, ë§Œì¼ì„ ìœ„í•´ ë‚¨ê²¨ë‘¡ë‹ˆë‹¤.
    session = make_session()
    url = "https://m.oliveyoung.co.kr/m/mtn/ranking/getBrandRanking.do"
    try:
        r = session.get(url, timeout=15)
        if r.status_code != 200: return None, r.text[:500]
        items = parse_brand_html(r.text)
        return (items, r.text[:500]) if items else (None, r.text[:500])
    except Exception:
        return None, "HTTP Request Exception"

# --- âœ¨ Stealth ëª¨ë“œê°€ ì ìš©ëœ Playwright í•¨ìˆ˜ ---
def try_playwright_for_brands_stealth():
    if not PLAYWRIGHT_AVAILABLE:
        logging.warning("Playwright not available.")
        return None, None
    
    ranking_url = "https://m.oliveyoung.co.kr/m/mtn/ranking/getBrandRanking.do"
    
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True, args=["--no-sandbox", "--disable-dev-shm-usage"])
            context = browser.new_context(
                user_agent="Mozilla/5.0 (iPhone; CPU iPhone OS 17_5_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17_5 Mobile/15E148 Safari/604.1",
                locale="ko-KR",
                viewport={'width': 390, 'height': 844}
            )
            page = context.new_page()
            
            # âœ¨ Stealth ëª¨ë“œ ì ìš© âœ¨
            stealth_sync(page)

            logging.info("Playwright (Stealth): Navigating to brand ranking page.")
            # í˜ì´ì§€ ë¡œë“œê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ìµœëŒ€ 60ì´ˆ ëŒ€ê¸°
            page.goto(ranking_url, wait_until="networkidle", timeout=60000)
            
            try:
                # ë­í‚¹ ë¦¬ìŠ¤íŠ¸ê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ìµœëŒ€ 30ì´ˆ ëŒ€ê¸°
                page.wait_for_selector("div.rank_brand_list > ul > li", timeout=30000)
                logging.info("Playwright (Stealth): Ranking list element found successfully.")
            except Exception as e:
                page.screenshot(path=SCREENSHOT_PATH)
                logging.error("Playwright (Stealth): Timeout waiting for selector. Debug screenshot saved.")
                raise e

            html = page.content()
            items = parse_brand_html(html)
            browser.close()
            return items, html[:500]
            
    except Exception as e:
        logging.exception("Playwright (Stealth) render error: %s", e)
        return None, f"Playwright (Stealth) failed. Check screenshot. Error: {str(e)}"

# ... (Google Drive, ë¶„ì„, Slack í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€) ...
def build_drive_service_oauth():
    # ...
def upload_csv_to_drive(service, csv_bytes, filename, folder_id=None):
    # ...
def find_csv_by_exact_name(service, folder_id: str, filename: str):
    # ...
def download_file_from_drive(service, file_id):
    # ...
def analyze_brand_trends(today_items, prev_items, top_window=TOP_WINDOW):
    # ...
def send_slack_text(text):
    # ...

# ---------------- ë©”ì¸
def main():
    now_kst = kst_now()
    today_kst = now_kst.date()
    yesterday_kst = (now_kst - timedelta(days=1)).date()
    logging.info("Build: oy-brand-rank-app %s", today_kst.isoformat())

    # --- âœ¨ ìˆ˜ì •ëœ í¬ë¡¤ë§ ë¡œì§: ì´ì œ Playwrightë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš© ---
    logging.info("Start scraping brand ranking (Playwright Stealth First)")
    items, sample = try_playwright_for_brands_stealth()

    if not items:
        # ë§Œì•½ì„ ìœ„í•œ HTTP ì¬ì‹œë„
        logging.warning("Playwright failed, trying HTTP request as a last resort.")
        items, sample = fetch_brand_ranking_data()

    if not items:
        logging.error("Scraping failed completely. sample head: %s", (sample or "")[:500])
        send_slack_text(f"âŒ OliveYoung Mobile Brand Ranking scraping failed.\nLast message: {(sample or '')[:800]}")
        return 1
    
    # ... (CSV ìƒì„± ë° ì´í›„ ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼) ...
    os.makedirs(OUT_DIR, exist_ok=True)
    fname_today = f"ì˜¬ë¦¬ë¸Œì˜_ë¸Œëœë“œë­í‚¹_{today_kst.isoformat()}.csv"
    header = ["rank", "brand_name", "representative_product", "url"]
    def q(s):
        if s is None: return ""
        s = str(s).replace('"', '""'); return f'"{s}"' if any(c in s for c in [',', '\n', '"']) else s
    lines = [",".join(header)]
    for it in items: lines.append(",".join([q(it.get(h)) for h in header]))
    csv_data = "\n".join(lines).encode("utf-8")
    path = os.path.join(OUT_DIR, fname_today)
    with open(path, "wb") as f: f.write(csv_data)
    logging.info("Saved CSV locally: %s", path)

    drive_service = build_drive_service_oauth()
    if drive_service and GDRIVE_FOLDER_ID:
        upload_csv_to_drive(drive_service, csv_data, fname_today, folder_id=GDRIVE_FOLDER_ID)
    
    prev_items = None
    if drive_service and GDRIVE_FOLDER_ID:
        fname_yesterday = f"ì˜¬ë¦¬ë¸Œì˜_ë¸Œëœë“œë­í‚¹_{yesterday_kst.isoformat()}.csv"
        y_file = find_csv_by_exact_name(drive_service, GDRIVE_FOLDER_ID, fname_yesterday)
        if y_file:
            prev_csv_text = download_file_from_drive(drive_service, y_file.get("id"))
            if prev_csv_text:
                prev_items = []
                try:
                    import csv
                    sio = StringIO(prev_csv_text)
                    rdr = csv.DictReader(sio)
                    for r in rdr:
                        try: r['rank'] = int(r.get('rank', 0)); prev_items.append(r)
                        except (ValueError, TypeError): continue
                except Exception: pass
    
    up, down, chart_ins, rank_out, in_out_count = analyze_brand_trends(items, prev_items or [], TOP_WINDOW)

    title = f"*ì˜¬ë¦¬ë¸Œì˜ ëª¨ë°”ì¼ ë¸Œëœë“œ ë­í‚¹ 100* ({now_kst.strftime('%Y-%m-%d %H:%M KST')})"
    out_lines = [title]
    out_lines.append("\n*ğŸ† TOP 10 ë¸Œëœë“œ*")
    for it in items[:10]: out_lines.append(f"{it.get('rank')}. <{it.get('url')}|{it.get('brand_name')}>")
    def fmt_brand_move(brand, prev, cur): return f"- {brand} {prev}ìœ„ â†’ {cur}ìœ„ ({'â†‘' if prev > cur else 'â†“'}{abs(prev - cur)})"
    out_lines.append("\n*ğŸ”¥ ê¸‰ìƒìŠ¹*")
    for m in up[:3]: out_lines.append(fmt_brand_move(m["brand_name"], m["prev_rank"], m["rank"]))
    out_lines.append("\n*ğŸ†• ë‰´ë­ì»¤*")
    for t in chart_ins[:3]: out_lines.append(f"- {t['brand_name']} NEW â†’ {t['rank']}ìœ„")
    out_lines.append("\n*ğŸ“‰ ê¸‰í•˜ë½ & ë­í¬ì•„ì›ƒ*")
    for m in down[:3]: out_lines.append(fmt_brand_move(m["brand_name"], m["prev_rank"], m["rank"]))
    for ro in rank_out[:2]: out_lines.append(f"- {ro['brand_name']} {ro['rank']}ìœ„ â†’ OUT")
    out_lines.append(f"\n*â†” ë­í¬ ì¸&ì•„ì›ƒ*: {in_out_count}ê°œ ë¸Œëœë“œ ë³€ë™")

    send_slack_text("\n".join(out_lines))
    logging.info("Done.")
    return 0

if __name__ == "__main__":
    exit(main())
